논리 회귀
	머신 러닝에서, 입력 값과, 범주 사이의 관계를 구하는 것
전처리
	실제 업무에서 얻는 데이터는 오기입하는 경우도 있고 단위와 분포가 제각각이기 때문에 작업 전 필수적으로 해야하는 정제작업

Logistic function(=Sigmoid function)
	로지스틱 함수는 입력값(x)으로 어떤 값이든 받을 수가 있지만 출력 결과(y)는 항상 0에서 1사이 값
	실제 많은 자연, 사회현상에서는 특정 변수에 대한 확률이 선형이 아닌 S 커브 형태를 따르는 경우가 많음 => 로지스틱함수( 딥러닝에서는 시그모이드(Sigmoid function) )
	
	x(입력)가 음수 방향으로 갈 수록 y(출력)가 0에 가까워지고,
	x(입력)가 양수 방향으로 갈 수록 y(출력)가 1에 가까워진다!
	즉, 시그모이드 함수를 통과하면 0 에서 1 사이 값이 나온다!!!

손실함수(  Binary Cross Entropy )
	우리의 목표는 모델을 통해 입력에 대한 어떤 확률적 예측(probabilitic prediction)을 하는 것이며, 이 예측이 ground-truth probabilities와 최대한 유사하게끔 모델 파라미터를 조정하는 것
